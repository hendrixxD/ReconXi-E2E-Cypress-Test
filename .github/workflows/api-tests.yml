
name: CI/CD For Test Automation

on:
  push:
    branches: testing
  pull_request:
    branches: main

jobs:
  api-tests:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Newman and Newman Reporter HTML
        run: |
          npm install -g newman newman-reporter-json newman-reporter-html newman-reporter-htmlextra newman-reporter-junit
      
      - name: Create Directories
        run: |
          mkdir -p ./newman/logs
          mkdir -p ./newman/reports
      
      - name: Run API Tests with Newman
        id: run_tests
        run: |
          # Run Newman with JSON reporter for parsing results
          newman run ./postman/collections/Reconxi_postman_collection.json \
            --reporters cli,htmlextra,junit,json \
            --reporter-htmlextra-export ./newman/reports/htmlreport.html \
            --reporter-junit-export ./newman/reports/junitreport.xml \
            --reporter-json-export ./newman/reports/jsonreport.json || true
          
          # Store the exit code
          echo "::set-output name=newman_exit_code::$?"
          
          # Create a timestamp for the log
          echo "API Test Execution - $(date)" > ./newman/logs/api_logs.txt
          echo "=================================================" >> ./newman/logs/api_logs.txt
          
          # Parse JSON report to create the log file
          node -e '
            const fs = require("fs");
            try {
              const jsonReport = JSON.parse(fs.readFileSync("./newman/reports/jsonreport.json", "utf8"));
              
              const logStream = fs.createWriteStream("./newman/logs/api_logs.txt", {flags: "a"});
              
              logStream.write(`Collection: ${jsonReport.collection.info.name}\n`);
              logStream.write(`Total Requests: ${jsonReport.run.stats.requests.total}\n`);
              logStream.write(`Total Tests: ${jsonReport.run.stats.assertions.total}\n`);
              logStream.write(`Passed Tests: ${jsonReport.run.stats.assertions.total - jsonReport.run.stats.assertions.failed}\n`);
              logStream.write(`Failed Tests: ${jsonReport.run.stats.assertions.failed}\n\n`);
              
              logStream.write("DETAILED TEST RESULTS\n");
              logStream.write("===================\n\n");
              
              jsonReport.run.executions.forEach((execution) => {
                logStream.write(`[REQUEST] ${execution.item.name}\n`);
                
                if (execution.assertions && execution.assertions.length > 0) {
                  execution.assertions.forEach((assertion) => {
                    const status = assertion.error ? "❌ FAILED" : "✅ PASSED";
                    logStream.write(`  ${status} - ${assertion.assertion}\n`);
                    
                    if(assertion.error) {
                      logStream.write(`    Error: ${assertion.error.message}\n`);
                      if (assertion.error.expected) logStream.write(`    Expected: ${assertion.error.expected}\n`);
                      if (assertion.error.actual) logStream.write(`    Actual: ${assertion.error.actual}\n`);
                    }
                  });
                } else {
                  logStream.write(`  ⚠️ NO TESTS for this request\n`);
                }
                
                logStream.write("\n");
              });
              
              logStream.write("END OF TEST LOG\n");
              logStream.end();
              console.log("Log file created successfully");
            } catch (error) {
              console.error("Error processing JSON report:", error);
              fs.appendFileSync("./newman/logs/api_logs.txt", 
                "\nERROR: Failed to process JSON report. Newman execution may have failed.\n" +
                "Error details: " + error.message + "\n" +
                "END OF TEST LOG\n"
              );
            }
          '
      - name: List generated reports
        run: ls -la ./newman/reports/
        
      - name: Check Test Results
        run: |
          # First check if Newman ran successfully by examining reports directory
          echo "Checking for report files..."
          ls -la ./newman/reports/ || echo "Reports directory is empty or doesn't exist"
          
          # Then check specifically for the JUnit report
          if [ -f "./newman/reports/junitreport.xml" ]; then
            echo "Test execution completed. JUnit report found."
            cat ./newman/logs/api_logs.txt || echo "Log file not found"
          else
            echo "Test execution failed. JUnit report not found."
            cat ./newman/logs/api_logs.txt || echo "Log file not found"
            exit 1
          fi
      
      - name: Upload Test Reports and Logs
        uses: actions/upload-artifact@v4
        if: always() # Upload reports even if tests fail
        with:
          name: newman-test-reports
          path: |
            ./newman/reports/
            ./newman/logs/
          retention-days: 7